import json
import requests
import warnings
import re
import os
import time
from urllib3.exceptions import InsecureRequestWarning
from copy import deepcopy

# å…¨å±€å˜é‡
last_site = None
successful_urls = []

# æ—¥å¿—å‡½æ•°ä¿æŒä¸å˜
def log_message(message, site_name=None, step="", max_error_length=80):
    global last_site
    status_emojis = {
        '[å¼€å§‹]': 'ğŸš€', '[æˆåŠŸ]': 'âœ…', '[å®Œæˆ]': 'ğŸ‰', '[å¤±è´¥]': 'âŒ',
        '[è¶…æ—¶]': 'â³', '[è­¦å‘Š]': 'âš ï¸', '[é”™è¯¯]': 'ğŸš¨', '[ä¿¡æ¯]': 'â„¹ï¸',
        '[é€‰æ‹©]': 'ğŸ”', '[è¿æ¥å¤±è´¥]': 'ğŸ”Œ'
    }
    if site_name and site_name != last_site:
        print(f"\n{'âœ¨ ' + '=' * 38 + ' âœ¨'}")
        print(f"ğŸŒ [ç«™ç‚¹: {site_name}]")
        print(f"{'âœ¨ ' + '=' * 38 + ' âœ¨'}")
        last_site = site_name
    for status, emoji in status_emojis.items():
        if status in message:
            message = message.replace(status, f"{status} {emoji}")
            break
    else:
        message = f"{message} ğŸ“¢"
    if "[è¿æ¥å¤±è´¥]" in message or "[é”™è¯¯]" in message:
        if len(message) > max_error_length:
            message = message[:max_error_length] + "..."
    print(f"[{time.strftime('%Y-%m-%d %H:%M:%S')}] [{step}] {message}") if step else print(message)

# ä¿®æ”¹åçš„ç«™ç‚¹æ˜ å°„
site_mappings = {
    'ç«‹æ’­': 'libo', 'é—ªç”µ': 'shandian', 'æ¬§å“¥': 'ouge', 'å°ç±³': 'xiaomi', 'å¤šå¤š': 'duoduo',
    'èœ¡ç¬”': 'labi', 'è‡³è‡»': 'zhizhen', 'æœ¨å¶': 'mogg', 'å…­è¶£': 'liuqu', 'è™æ–‘': 'huban',
    'ä¸‹é¥­': 'xiafan', 'ç©å¶': 'wogg', 'æ˜Ÿå‰§ç¤¾': 'star2'
}

# ä¿®æ”¹åçš„ JSM æ˜ å°„
jsm_mapping = {
    "Libvio": "libo", "Xiaomi": "xiaomi", "yydsys": "duoduo", "èœ¡ç¬”ç½‘ç›˜": "labi",
    "ç©å¶ | èœ¡ç¬”": "labi", "è‡³è‡»|ç½‘ç›˜": "zhizhen", "Huban": "huban", "Wogg": "wogg",
    "Mogg": "mogg", "ç©å¶ | é—ªç”µuc": "shandian",
    "ç©å¶ | å°ç±³": "xiaomi", "ç©å¶ | å¤šå¤š": "duoduo", "ç©å¶ | æœ¨å¶": "mogg",
    "ç©å¶gg": "wogg", "æ˜Ÿå‰§ç¤¾": "star2", "å¤¸å…‹è‡³è‡»å¼¹å¹•": "zhizhen",
    "ç©å¶": "wogg"
}

# ä¿®æ”¹åçš„å…œåº• URL é…ç½®
fallback_url_config = {
    "ç«‹æ’­": [
        "https://libvio.mov", "https://www.libvio.cc", "https://libvio.la",
        "https://libvio.pro", "https://libvio.fun", "https://libvio.me",
        "https://libvio.in", "https://libvio.site", "https://libvio.art",
        "https://libvio.com", "https://libvio.vip", "https://libvio.pw",
        "https://libvio.link"
    ],
    "é—ªç”µ": ["http://1.95.79.193", "http://1.95.79.193:666"],
    "æ¬§å“¥": ["https://woog.nxog.eu.org"],
    "å°ç±³": [
        "http://www.54271.fun", "https://www.milvdou.fun", "http://www.54271.fun",
        "https://www.mucpan.cc", "https://mucpan.cc", "http://milvdou.fun"
    ],
    "å¤šå¤š": [
        "https://tv.yydsys.top", "https://tv.yydsys.cc", "https://tv.214521.xyz",
        "http://155.248.200.65"
    ],
    "èœ¡ç¬”": ["http://feimaoai.site", "https://feimao666.fun", "http://feimao888.fun"],
    "è‡³è‡»": [
        "https://mihdr.top", "http://www.miqk.cc", "https://xiaomiai.site"
    ],
    "å…­è¶£": ["https://wp.0v.fit"],
    "è™æ–‘": ["http://103.45.162.207:20720"],
    "ä¸‹é¥­": ["http://txfpan.top", "http://www.xn--ghqy10g1w0a.xyz"],
    "ç©å¶": [
        "https://wogg.xxooo.cf", "https://wogg.333232.xyz", "https://www.wogg.one",
        "https://www.wogg.lol", "https://www.wogg.net"
    ],
    "æœ¨å¶": [
        "https://tv.91muou.icu", "https://mo.666291.xyz", "https://mo.muouso.fun",
        "https://aliii.deno.dev", "http://149.88.87.72:5666"
    ],
    "æ˜Ÿå‰§ç¤¾": ["https://mlink.cc/520TV"]
}

# å…¶ä½™å‡½æ•°ä¿æŒä¸å˜
# æ–‡ä»¶è·¯å¾„å¤„ç†
def get_file_path(filename):
    return f"./{filename}"

# åŠ è½½ 2024.json
def load_jsm_config():
    jsm_path = get_file_path('2024.json')
    if os.path.exists(jsm_path):
        try:
            with open(jsm_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                log_message(f"[æˆåŠŸ] è¯»å– 2024.json: {jsm_path}", step="é…ç½®åŠ è½½")
                return data
        except Exception as e:
            log_message(f"[é”™è¯¯] è¯»å– 2024.json å¤±è´¥: {str(e)}", step="é…ç½®åŠ è½½")
            return {}
    else:
        log_message(f"[é”™è¯¯] 2024.json ä¸å­˜åœ¨: {jsm_path}", step="é…ç½®åŠ è½½")
        return {}

# åŠ è½½ç°æœ‰ url.json
def load_existing_config():
    url_path = get_file_path('url.json')
    if os.path.exists(url_path):
        try:
            with open(url_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                log_message(f"[æˆåŠŸ] è¯»å– url.json: {url_path}", step="é…ç½®åŠ è½½")
                return data
        except Exception as e:
            log_message(f"[é”™è¯¯] è¯»å– url.json å¤±è´¥: {str(e)}", step="é…ç½®åŠ è½½")
            return {}
    return {}

# æµ‹è¯• URL å¹¶è®°å½•æˆåŠŸç»“æœ
def test_url(url, site_name=None):
    global successful_urls
    try:
        response = requests.get(
            url,
            timeout=7,
            verify=False,
            headers={'User-Agent': 'Mozilla/5.0'}
        )
        if response.status_code == 200:
            latency = response.elapsed.total_seconds()
            log_message(f"[æˆåŠŸ] {url} | å»¶è¿Ÿ: {latency:.2f}s", site_name, "URLæµ‹è¯•")
            successful_urls.append(f"{site_name}: {url} (å»¶è¿Ÿ: {latency:.2f}s)")
            return latency
        log_message(f"[å¤±è´¥] HTTPçŠ¶æ€ç  {response.status_code}", site_name, "URLæµ‹è¯•")
    except Exception as e:
        log_message(f"[è¿æ¥å¤±è´¥] {str(e)}", site_name, "URLæµ‹è¯•")
    return None

# è·å–æœ€ä½³ URL
def get_best_url(urls, site_name=None, existing_url=None):
    if not isinstance(urls, list):
        return urls
    for url in urls:
        latency = test_url(url, site_name)
        if latency is not None:
            log_message(f"[é€‰æ‹©] é€‰ä¸­ {url}", site_name, "URLé€‰æ‹©")
            return url
    log_message(f"[è­¦å‘Š] æ— å¯ç”¨URLï¼Œä½¿ç”¨ç°æœ‰: {existing_url}", site_name, "URLé€‰æ‹©")
    return existing_url

# æ˜Ÿå‰§ç¤¾ç‰¹æ®Šå¤„ç†
def get_star2_real_url(source_url):
    try:
        response = requests.get(
            source_url,
            timeout=8,
            verify=False,
            headers={'Referer': 'https://mlink.cc/'}
        )
        if response.status_code == 200:
            match = re.search(r'(?:href|src|data-?url)=["\'](https?://[^"\']*?star2\.cn[^"\']*)["\']', response.text, re.I)
            if match:
                real_url = match.group(1).strip().rstrip('/')
                log_message(f"[æˆåŠŸ] æå–çœŸå®é“¾æ¥: {real_url}", "æ˜Ÿå‰§ç¤¾", "é“¾æ¥è§£æ")
                return real_url
        log_message("[å¤±è´¥] æœªæ‰¾åˆ°æœ‰æ•ˆé“¾æ¥", "æ˜Ÿå‰§ç¤¾", "é“¾æ¥è§£æ")
    except Exception as e:
        log_message(f"[é”™è¯¯] è§£æå¤±è´¥: {str(e)}", "æ˜Ÿå‰§ç¤¾", "é“¾æ¥è§£æ")
    return None

# æ•°æ®åˆå¹¶å»é‡
def merge_url_data(*dicts):
    merged = {}
    for d in dicts:
        if not d: continue
        for site, urls in d.items():
            merged.setdefault(site, []).extend(urls if isinstance(urls, list) else [urls])
    return {k: list(dict.fromkeys(v)) for k, v in merged.items()}

# æ›¿æ¢ URL
def replace_urls(data, urls):
    if not isinstance(data, dict) or 'sites' not in data:
        log_message("[é”™è¯¯] 2024.json ç¼ºå°‘ 'sites' å­—æ®µ", step="URLæ›¿æ¢")
        return data

    api_urls = {jsm_key: urls.get(jsm_value) for jsm_key, jsm_value in jsm_mapping.items()}
    sites = data['sites']
    replaced_count = 0

    for item in sites:
        if not isinstance(item, dict):
            continue
        key = item.get('key')
        ext = item.get('ext')
        new_url = api_urls.get(key)

        if not new_url:
            log_message(f"[è­¦å‘Š] æœªæ‰¾åˆ° {key} çš„æ–° URL", step="URLæ›¿æ¢")
            continue

        if isinstance(ext, dict):
            old_url = ext.get('siteUrl') or ext.get('site')
            target_key = 'siteUrl' if 'siteUrl' in ext else 'site'
            if old_url and old_url != new_url:
                ext[target_key] = new_url
                replaced_count += 1
                log_message(f"[æˆåŠŸ] æ›¿æ¢ {key} çš„ {target_key}: {old_url} -> {new_url}", step="URLæ›¿æ¢")
            elif not old_url:
                ext[target_key] = new_url
                replaced_count += 1
                log_message(f"[æˆåŠŸ] æ·»åŠ  {key} çš„ {target_key}: {new_url}", step="URLæ›¿æ¢")
        elif isinstance(ext, str):
            parts = ext.split('$$$')
            if len(parts) > 1 and parts[1].strip().startswith('http'):
                old_url = parts[1]
                if old_url != new_url:
                    parts[1] = new_url
                    item['ext'] = '$$$'.join(parts)
                    replaced_count += 1
                    log_message(f"[æˆåŠŸ] æ›¿æ¢ {key}: {old_url} -> {new_url}", step="URLæ›¿æ¢")
            else:
                if ext != new_url:
                    item['ext'] = new_url
                    replaced_count += 1
                    log_message(f"[æˆåŠŸ] è®¾ç½® {key} çš„ ext: {new_url}", step="URLæ›¿æ¢")
        elif ext is None:
            item['ext'] = {'site': new_url}
            replaced_count += 1
            log_message(f"[æˆåŠŸ] æ·»åŠ  {key} çš„ site: {new_url}", step="URLæ›¿æ¢")
        if 'url' in item:
            del item['url']

    log_message(f"[å®Œæˆ] æ€»å…±æ›¿æ¢äº† {replaced_count} ä¸ªé“¾æ¥", step="URLæ›¿æ¢")
    return data

# æ›´æ–° 2024.jsonï¼Œä¿ç•™åŸå§‹æ ¼å¼
def update_jsm_config(urls):
    jsm_path = get_file_path('2024.json')
    if not os.path.exists(jsm_path):
        log_message(f"[é”™è¯¯] 2024.json ä¸å­˜åœ¨: {jsm_path}", step="é…ç½®æ›´æ–°")
        return False

    # å¤‡ä»½åŸå§‹æ–‡ä»¶
    backup_path = f"{jsm_path}.bak"
    try:
        with open(jsm_path, 'r', encoding='utf-8') as f:
            original_content = f.read()
            if not original_content.strip():
                log_message("[é”™è¯¯] 2024.json æ–‡ä»¶ä¸ºç©ºï¼Œä¸è¿›è¡Œæ“ä½œ", step="é…ç½®æ›´æ–°")
                return False
            with open(backup_path, 'w', encoding='utf-8') as backup:
                backup.write(original_content)
        log_message(f"[æˆåŠŸ] å¤‡ä»½ 2024.json åˆ° {backup_path}", step="é…ç½®æ›´æ–°")
    except Exception as e:
        log_message(f"[é”™è¯¯] å¤‡ä»½å¤±è´¥: {str(e)}", step="é…ç½®æ›´æ–°")
        return False

    # åŠ è½½åŸå§‹ JSON æ•°æ®
    try:
        with open(jsm_path, 'r', encoding='utf-8') as f:
            jsm_data = json.load(f)
    except Exception as e:
        log_message(f"[é”™è¯¯] è§£æ 2024.json å¤±è´¥: {str(e)}", step="é…ç½®æ›´æ–°")
        return False

    # ç¡®ä¿ jsm_data åŒ…å« sites å­—æ®µ
    if not isinstance(jsm_data, dict) or 'sites' not in jsm_data:
        log_message("[é”™è¯¯] 2024.json ç¼ºå°‘ 'sites' å­—æ®µï¼Œä¸è¿›è¡Œæ“ä½œ", step="é…ç½®æ›´æ–°")
        return False

    if not jsm_data['sites']:
        log_message("[é”™è¯¯] 2024.json ä¸­ 'sites' å­—æ®µä¸ºç©ºï¼Œä¸è¿›è¡Œæ“ä½œ", step="é…ç½®æ›´æ–°")
        return False

    # æ›¿æ¢ URL
    updated_data = replace_urls(deepcopy(jsm_data), urls)
    if not updated_data or not updated_data.get('sites'):
        log_message("[é”™è¯¯] æ›´æ–°åæ•°æ®ä¸ºç©ºæˆ–ç¼ºå°‘ 'sites' å­—æ®µï¼Œä¸è¦†ç›–æ–‡ä»¶", step="é…ç½®æ›´æ–°")
        return False

    # è¯»å–åŸå§‹æ–‡ä»¶å†…å®¹ï¼ˆé€è¡Œï¼‰
    try:
        with open(jsm_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()
    except Exception as e:
        log_message(f"[é”™è¯¯] è¯»å–åŸå§‹æ–‡ä»¶å†…å®¹å¤±è´¥: {str(e)}", step="é…ç½®æ›´æ–°")
        return False

    # æ„å»ºæ›´æ–°åçš„å†…å®¹ï¼Œä¿ç•™åŸå§‹æ ¼å¼
    formatted_lines = []
    site_index = 0
    sites = updated_data['sites']
    in_sites = False

    for line in lines:
        line = line.rstrip()
        if '"sites": [' in line:
            in_sites = True
            formatted_lines.append(line)
            continue
        if in_sites and site_index < len(sites):
            if line.strip().startswith('{'):
                # ä½¿ç”¨æ›¿æ¢åçš„ item æ„é€ æ–°è¡Œ
                item = sites[site_index]
                # æå–åŸå§‹è¡Œçš„ç¼©è¿›
                indent = len(line) - len(line.lstrip())
                # æ„é€ æ–°è¡Œï¼Œä¿ç•™åŸå§‹æ ¼å¼
                new_line = ' ' * indent + '{'
                # æŒ‰å­—æ®µé¡ºåºæ„é€ ï¼Œä¿æŒåŸå§‹é¡ºåº
                fields = []
                for key in item:
                    if key == 'ext':
                        # ç‰¹æ®Šå¤„ç† ext å­—æ®µ
                        if isinstance(item[key], dict):
                            fields.append(f'"ext": {json.dumps(item[key], ensure_ascii=False)}')
                        elif isinstance(item[key], str):
                            fields.append(f'"ext": "{item[key]}"')
                        else:
                            fields.append(f'"ext": {json.dumps(item[key], ensure_ascii=False)}')
                    else:
                        if isinstance(item[key], (int, bool)):
                            fields.append(f'"{key}": {item[key]}')
                        elif isinstance(item[key], (dict, list)):
                            fields.append(f'"{key}": {json.dumps(item[key], ensure_ascii=False)}')
                        else:
                            fields.append(f'"{key}": "{item[key]}"')
                new_line += ' ' + ', '.join(fields) + ' }'
                if site_index < len(sites) - 1:
                    new_line += ','
                formatted_lines.append(new_line)
                site_index += 1
            else:
                formatted_lines.append(line)
        else:
            in_sites = False
            formatted_lines.append(line)

    # è°ƒè¯•ï¼šè¾“å‡ºç”Ÿæˆçš„ formatted_lines
    log_message(f"[è°ƒè¯•] ç”Ÿæˆçš„ formatted_lines: {formatted_lines}", step="é…ç½®æ›´æ–°")

    # å†™å…¥æ›´æ–°åçš„æ–‡ä»¶
    try:
        with open(jsm_path, 'w', encoding='utf-8') as f:
            f.write("\n".join(formatted_lines))
        log_message(f"[å®Œæˆ] 2024.json æ›´æ–°æˆåŠŸ: {jsm_path}", step="é…ç½®æ›´æ–°")
        return True
    except Exception as e:
        log_message(f"[é”™è¯¯] 2024.json æ›´æ–°å¤±è´¥: {str(e)}", step="é…ç½®æ›´æ–°")
        return False

# ä¿å­˜æˆåŠŸçš„ URL åˆ°æ–‡ä»¶
def save_successful_urls():
    path = get_file_path('URL_sucsses.txt')
    try:
        with open(path, 'w', encoding='utf-8') as f:
            f.write("\n".join(successful_urls))
        log_message(f"[æˆåŠŸ] ä¿å­˜æˆåŠŸ URL åˆ°: {path}", step="æ•°æ®æŒä¹…åŒ–")
    except Exception as e:
        log_message(f"[é”™è¯¯] ä¿å­˜ URL_sucsses.txt å¤±è´¥: {str(e)}", step="æ•°æ®æŒä¹…åŒ–")

# ä¸»æµç¨‹
def process_urls():
    global successful_urls
    successful_urls = []
    log_message("[å¼€å§‹] å¯åŠ¨URLæ›´æ–°æµç¨‹", step="ä¸»æµç¨‹")

    existing_config = load_existing_config()
    reverse_site_mapping = {v: k for k, v in site_mappings.items()}

    data_sources = []
    try:
        remote_data = requests.get(
            'https://github.catvod.com/https://raw.githubusercontent.com/celin1286/xiaosa/main/yuan.json',
            timeout=10
        ).json()
        data_sources.append(remote_data)
        log_message("[æˆåŠŸ] è¿œç¨‹æ•°æ®åŠ è½½å®Œæˆ", step="æ•°æ®æ”¶é›†")
    except Exception as e:
        log_message(f"[é”™è¯¯] è¿œç¨‹æ•°æ®è·å–å¤±è´¥: {str(e)}", step="æ•°æ®æ”¶é›†")

    local_path = get_file_path('yuan.json')
    if os.path.exists(local_path):
        try:
            with open(local_path, 'r', encoding='utf-8') as f:
                data_sources.append(json.load(f))
                log_message("[æˆåŠŸ] æœ¬åœ°æ•°æ®åŠ è½½å®Œæˆ", step="æ•°æ®æ”¶é›†")
        except Exception as e:
            log_message(f"[é”™è¯¯] æœ¬åœ°æ•°æ®è¯»å–å¤±è´¥: {str(e)}", step="æ•°æ®æ”¶é›†")

    data_sources.append(fallback_url_config)
    merged_data = merge_url_data(*data_sources)

    result = {'url': {}}
    stats = {'total': 0, 'success': 0, 'failed': [], 'changed': []}

    for cn_name, urls in merged_data.items():
        stats['total'] += 1
        site_key = site_mappings.get(cn_name)
        existing_url = existing_config.get(site_key, '')

        if cn_name == 'æ˜Ÿå‰§ç¤¾':
            best_source = get_best_url(urls, cn_name, existing_url)
            final_url = get_star2_real_url(best_source) if best_source else existing_url
        else:
            final_url = get_best_url(urls, cn_name, existing_url) or existing_url

        if final_url:
            result['url'][site_key] = final_url
            if existing_url and existing_url != final_url:
                stats['changed'].append(f"{cn_name}: {existing_url} -> {final_url}")
                log_message(f"[æ›´æ–°] é…ç½®å˜æ›´æ£€æµ‹", cn_name, "ç»“æœå¤„ç†")
            stats['success'] += 1
        else:
            stats['failed'].append(cn_name)
            log_message("[è­¦å‘Š] æ— å¯ç”¨URL", cn_name, "ç»“æœå¤„ç†")

    output_files = {
        'yuan.json': merged_data,
        'url.json': result['url']
    }
    for filename, data in output_files.items():
        path = get_file_path(filename)
        try:
            with open(path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            log_message(f"[æˆåŠŸ] ä¿å­˜æ–‡ä»¶: {path}", step="æ•°æ®æŒä¹…åŒ–")
        except Exception as e:
            log_message(f"[é”™è¯¯] æ–‡ä»¶ä¿å­˜å¤±è´¥: {str(e)}", step="æ•°æ®æŒä¹…åŒ–")

    save_successful_urls()

    log_message("[å¼€å§‹] å¯åŠ¨jsmé…ç½®æ›´æ–°", step="ä¸»æµç¨‹")
    update_success = update_jsm_config(result['url'])
    log_message(f"[{'æˆåŠŸ' if update_success else 'å¤±è´¥'}] jsmé…ç½®æ›´æ–°å®Œæˆ", step="ä¸»æµç¨‹")

    log_message(
        f"[å®Œæˆ] å¤„ç†ç»“æœ: {stats['success']}/{stats['total']} æˆåŠŸ\n"
        f"url.jsonå˜æ›´é¡¹ ({len(stats['changed'])}): {', '.join(stats['changed']) if stats['changed'] else 'æ— '}\n"
        f"url.jsonå¤±è´¥é¡¹ ({len(stats['failed'])}): {', '.join(stats['failed']) if stats['failed'] else 'æ— '}",
        step="ç»Ÿè®¡æŠ¥å‘Š"
    )
    return stats['success'] > 0

# ä¸»å‡½æ•°
def main():
    warnings.simplefilter('ignore', InsecureRequestWarning)
    process_urls()

if __name__ == "__main__":
    start_time = time.time()
    main()
    elapsed = time.time() - start_time
    print(f"æ€»è€—æ—¶: {elapsed:.2f}ç§’")
